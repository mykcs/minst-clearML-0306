{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26f467e1df582a4b",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T11:05:36.963745Z",
     "start_time": "2024-03-06T11:05:36.395495Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3626, 0.5079, 0.7611],\n",
      "        [0.7902, 0.2441, 0.8031],\n",
      "        [0.8215, 0.3259, 0.6404],\n",
      "        [0.7041, 0.9193, 0.6032],\n",
      "        [0.0983, 0.7821, 0.0018]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6470d855cc69b83d",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T10:41:00.582513Z",
     "start_time": "2024-03-06T10:41:00.579814Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PYTHONPATH: /Users/myk/PycharmProjects/pythonProject\n",
      "PATH: /Users/myk/anaconda3/envs/wyy20231222/bin:/Users/myk/anaconda3/condabin:/opt/homebrew/bin:/opt/homebrew/sbin:/usr/local/bin:/System/Cryptexes/App/usr/bin:/usr/bin:/bin:/usr/sbin:/sbin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/local/bin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/bin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/appleinternal/bin:/Library/Apple/usr/bin:/usr/local/share/dotnet:~/.dotnet/tools:/Users/myk/Library/Application Support/JetBrains/Toolbox/scripts\n",
      "CUDA: False\n",
      "3.9.18 (main, Sep 11 2023, 08:25:10) \n",
      "[Clang 14.0.6 ]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"PYTHONPATH:\", os.environ.get('PYTHONPATH'))\n",
    "print(\"PATH:\", os.environ.get('PATH'))\n",
    "print(\"CUDA:\", torch.cuda.is_available())\n",
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4bbaa384cf55d0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-12T03:16:28.069976Z",
     "start_time": "2024-01-12T03:16:27.931527Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior_probabilit = {1: 10, -1: 7}\n",
      "conditional_probability =  {'-1,0,1': 3, '-1,1,S': 3, '-1,1,M': 2, '1,0,1': 2, '1,1,M': 4, '1,1,S': 1, '-1,0,2': 2, '1,0,2': 3, '1,1,L': 4, '1,0,3': 4, '-1,0,3': 1, '-1,1,L': 1}\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "conditional_probability =  {'-1,0,1': 0.4, '-1,1,S': 0.4, '-1,1,M': 0.3, '1,0,1': 0.23076923076923078, '1,1,M': 0.38461538461538464, '1,1,S': 0.15384615384615385, '-1,0,2': 0.3, '1,0,2': 0.3076923076923077, '1,1,L': 0.38461538461538464, '1,0,3': 0.38461538461538464, '-1,0,3': 0.2, '-1,1,L': 0.2}\n",
      "result = {1: 0.027845457709711106, -1: 0.04941176470588235}\n",
      " r_label = -1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    " \n",
    "def loaddata():\n",
    "    X = np.array([[1,'S'],[1,'M'],[1,'M'],[1,'S'],\n",
    "         [1, 'S'], [2, 'S'], [2, 'M'], [2, 'M'],\n",
    "         [2, 'L'], [2, 'L'], [3, 'L'], [3, 'M'],\n",
    "         [3, 'M'], [3, 'L'], [3, 'L']])\n",
    "    y = np.array([-1,-1,1,1,-1,-1,-1,1,1,1,1,1,1,1,-1])\n",
    "    return X, y\n",
    " \n",
    "# 训练、计算各个概率值\n",
    "def Train(trainset, train_labels):\n",
    "    # 数据量\n",
    "    m = trainset.shape[0]\n",
    "    # 特征数\n",
    "    n = trainset.shape[1]\n",
    "    # 先验概率,key是类别值，value是类别的概率值\n",
    "    prior_probability = {}\n",
    "    # 条件概率，key的构造：类别，特征，特征值,value是\n",
    "    conditional_probability = {}\n",
    " \n",
    "    # 类别的可能取值\n",
    "    labels = set(train_labels)\n",
    "    # 计算先验概率,此时没有计算总数据量m\n",
    "    for label in labels:\n",
    "        prior_probability[label] = len(train_labels[train_labels == label]) + 1\n",
    "    print('prior_probabilit =', prior_probability)\n",
    " \n",
    "    # 计算条件概率\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            # key的构造：类别，特征，特征值\n",
    "            key = str(train_labels[i]) + ',' + str(j) + ',' + str(trainset[i][j])\n",
    "            if key in conditional_probability:\n",
    "                conditional_probability[key] += 1\n",
    "            else:\n",
    "                conditional_probability[key] = 1\n",
    "    print('conditional_probability = ', conditional_probability)\n",
    " \n",
    "    # 因字典在循环时不能改变，故定义新字典来保存值\n",
    "    conditional_probability_final = {}\n",
    "    for key in conditional_probability:\n",
    "        # 取出当前的类别\n",
    "        label = key.split(',')[0]\n",
    "        key1 = key.split(',')[1]\n",
    "        Ni = len(set(trainset[:, int(key1)]))\n",
    "        print(Ni)\n",
    "        conditional_probability_final[key] = (conditional_probability[key] + 1) / (prior_probability[int(label)] +Ni)\n",
    " \n",
    "    # 最终先验概率（除以总数据量m）\n",
    "    for label in labels:\n",
    "        prior_probability[label] = prior_probability[label] / (m + len(labels))\n",
    " \n",
    "    return prior_probability, conditional_probability_final, labels\n",
    " \n",
    "# 定义预测函数\n",
    "def predict(data):\n",
    "    result = {}\n",
    "    # 循环标签\n",
    "    for label in train_labels_set:\n",
    "        temp = 1.0\n",
    "        for j in range(len(data)):\n",
    "            key = str(label) + ',' + str(j) + ',' + str(data[j])\n",
    "            # 条件概率连乘\n",
    "            temp = temp * conditional_probability[key]\n",
    "        # 在乘上先验概率\n",
    "        result[label] = temp * prior_probability[label]\n",
    "    print('result =', result)\n",
    "    # 排序返回标签值\n",
    "    return sorted(result.items(), key=lambda x: x[1], reverse=True)[0][0]\n",
    " \n",
    "X,y = loaddata()\n",
    "prior_probability,conditional_probability,train_labels_set = Train(X,y)\n",
    "print('conditional_probability = ', conditional_probability)\n",
    "r_label = predict([2,'S'])\n",
    "print(' r_label =', r_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5de3a28ca994914e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from matplotlib.colors import ListedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eeb8ad5f-2db3-45ad-9f43-eade03895ccb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-12T03:58:32.252427Z",
     "start_time": "2024-01-12T03:58:32.250256Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_plot(clf,title_str,X,y):\n",
    "    print(\"6\")\n",
    "    names = ['Sepal length, x1', 'Sepal width, x2'];\n",
    "    \n",
    "    # Create color maps\n",
    "    rgb = [[255, 238, 255],  # red\n",
    "           [219, 238, 244],  # blue\n",
    "           [228, 228, 228]]  # black\n",
    "    rgb = np.array(rgb)/255.\n",
    "    \n",
    "    cmap_light = ListedColormap(rgb)\n",
    "    cmap_bold = [[255, 51, 0], [0, 153, 255],[138,138,138]]\n",
    "    cmap_bold = np.array(cmap_bold)/255.\n",
    "    \n",
    "    plot_step = 0.02\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, plot_step),\n",
    "                         np.arange(y_min, y_max, plot_step))\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    # plot regions\n",
    "    plt.contourf(xx, yy, Z, cmap=cmap_light)\n",
    "    \n",
    "    # plot decision boundaries\n",
    "    plt.contour(xx, yy, Z, levels=[0,1,2], colors=np.array([0, 68, 138])/255.)\n",
    "    \n",
    "    plt.xlabel(names[0])\n",
    "    plt.ylabel(names[1])\n",
    "\n",
    "    # Plot the training points\n",
    "    sns.scatterplot(x=X[:, 0], y=X[:, 1], hue=iris.target_names[y],\n",
    "                    palette=cmap_bold, alpha=1.0, \n",
    "                    linewidth = 1, edgecolor=[1,1,1])\n",
    "    plt.title(title_str)\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "    plt.xticks(np.arange(4, 9, step=1))\n",
    "    plt.yticks(np.arange(2, 6, step=1))\n",
    "    plt.xlabel(iris.feature_names[0])\n",
    "    plt.ylabel(iris.feature_names[1])\n",
    "    ax.grid(linestyle='--', linewidth=0.25, color=[0.5,0.5,0.5])\n",
    "    plt.tight_layout()\n",
    "    plt.axis('scaled')\n",
    "\n",
    "    # plot tree structure\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    plot_tree(clf, filled=True,\n",
    "              feature_names=[names[0],names[1]], \n",
    "              rounded = True)\n",
    "    plt.title(title_str) \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e4f513c-2b9b-4aa6-a96b-348a1cdad0a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-12T03:59:23.822134Z",
     "start_time": "2024-01-12T03:59:23.820023Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected character after line continuation character (4016119680.py, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  Cell \u001B[0;32mIn[9], line 13\u001B[0;36m\u001B[0m\n\u001B[0;31m    train_plot(clf,title_str,X,y)\\]\u001B[0m\n\u001B[0m                                  ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m unexpected character after line continuation character\n"
     ]
    }
   ],
   "source": [
    "from sympy import python\n",
    "\n",
    "# Load data\n",
    "iris = load_iris()\n",
    "\n",
    "# Use the first two features\n",
    "X = iris.data[:, [0, 1]]\n",
    "y = iris.target\n",
    "\n",
    "# Varying max_leaf_nodes\n",
    "for max_leaf_nodes in [2,3,4,5,10,15,20]:\n",
    "\n",
    "    clf = DecisionTreeClassifier(max_leaf_nodes=max_leaf_nodes).fit(X, y)\n",
    "    title_str = \"Max leaf nodes = {:.0f}\".format(max_leaf_nodes)\n",
    "    train_plot(clf,title_str,X,y)\\]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It's a test:   0%|          | 0/20 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtqdm\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m tqdm, trange\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m tqdm(\u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m20\u001B[39m), desc\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mIt\u001B[39m\u001B[38;5;130;01m\\'\u001B[39;00m\u001B[38;5;124ms a test\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[0;32m----> 4\u001B[0m     \u001B[43mtime\u001B[49m\u001B[38;5;241m.\u001B[39msleep(\u001B[38;5;241m0.1\u001B[39m)\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tqdm(\u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m100\u001B[39m), desc\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTest\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m tbar:\n\u001B[1;32m      7\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m tbar:\n",
      "\u001B[0;31mNameError\u001B[0m: name 'time' is not defined"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm, trange\n",
    "    \n",
    "for i in tqdm(range(20), desc='It\\'s a test'):\n",
    "    time.sleep(0.1)\n",
    "\n",
    "with tqdm(range(100), desc='Test') as tbar:\n",
    "    for i in tbar:\n",
    "        tbar.set_postfix(loss=i/100, x=i)\n",
    "        tbar.update()  # 默认参数n=1，每update一次，进度+n\n",
    "        time.sleep(0.2)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T17:21:14.378193Z",
     "start_time": "2024-03-06T17:21:14.361448Z"
    }
   },
   "id": "58a5130ef47ac276",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection failed, status code: 401\n",
      "Missing authentication headers\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "response = requests.get('https://api.clear.ml')\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print('Connected to api.clear.ml successfully!')\n",
    "else:\n",
    "    print(f'Connection failed, status code: {response.status_code}')\n",
    "    print(response.text)  # This may have some error messages from the server\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T17:21:16.412531Z",
     "start_time": "2024-03-06T17:21:15.348375Z"
    }
   },
   "id": "a580992916e1d6cc",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "from einops.layers.torch import Rearrange\n",
    "from einops import rearrange\n",
    "\n",
    "import clearml\n",
    "from clearml import Task\n",
    "import numpy as np\n",
    "\n",
    "clearml.browser_login()\n",
    "\n",
    "# Always initialize ClearML before anything else. Automatic hooks will track as much as possible for you!\n",
    "task = Task.init(\n",
    "    project_name=\"pyPjct-minst-0306\",\n",
    "    task_name=\"Minst Training 03\",\n",
    "    output_uri=True  # IMPORTANT: setting this to True will upload the model\n",
    "    # If not set the local path of the model will be saved instead!\n",
    ")\n",
    "\n",
    "# 定义训练的设备\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"MPS is available. \")\n",
    "else:\n",
    "    if not torch.backends.mps.is_built():\n",
    "        print(\"MPS not available because the current PyTorch install was not \"\n",
    "              \"built with MPS enabled. \")\n",
    "    else:\n",
    "        print(\"MPS not available because the current MacOS version is not 12.3+ \"\n",
    "              \"and/or you do not have an MPS-enabled device on this machine. \")\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 准备数据集\n",
    "train_data = torchvision.datasets.MNIST(\"./data\", train=True, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "test_data = torchvision.datasets.MNIST(\"./data\", train=False, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "\n",
    "# 加载数据集\n",
    "train_dataloader = DataLoader(train_data, batch_size=256, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=256, shuffle=False)\n",
    "\n",
    "# 构建ViT模型\n",
    "class ViT(nn.Module):\n",
    "    def __init__(self, image_size, patch_size, num_classes, hidden_dim, num_heads, num_layers):\n",
    "        super(ViT, self).__init__()\n",
    "        num_patches = (image_size // patch_size) ** 2\n",
    "        patch_dim = 1 * patch_size ** 2\n",
    "\n",
    "        self.patch_embedding = nn.Sequential(\n",
    "            nn.Conv2d(1, hidden_dim, kernel_size=patch_size, stride=patch_size),\n",
    "            Rearrange('b c h w -> b (h w) c')\n",
    "        )\n",
    "\n",
    "        self.transformer = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=hidden_dim, nhead=num_heads),\n",
    "            num_layers=num_layers\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.patch_embedding(x)\n",
    "        x = rearrange(x, 'b n d -> n b d')  # 将序列维度放在第一维\n",
    "        x = self.transformer(x)\n",
    "        x = x.mean(dim=0)  # 取序列维度的平均值\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# 创建ViT模型实例\n",
    "image_size = 28\n",
    "patch_size = 7\n",
    "num_classes = 10\n",
    "hidden_dim = 64\n",
    "num_heads = 4\n",
    "num_layers = 4\n",
    "\n",
    "vit = ViT(image_size, patch_size, num_classes, hidden_dim, num_heads, num_layers)\n",
    "vit = vit.to(device)\n",
    "\n",
    "task.connect(vit.parameters())\n",
    "\n",
    "# 损失函数：交叉熵损失\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "loss_fn = loss_fn.to(device)\n",
    "\n",
    "# 优化器：随机梯度下降\n",
    "learning_rate = 0.01  # 学习速率\n",
    "optimizer = torch.optim.SGD(vit.parameters(), lr=learning_rate)\n",
    "\n",
    "'''\n",
    "# Make sure ClearML knows these parameters are our hyperparameters!\n",
    "task.connect(vit.parameters())\n",
    "'''\n",
    "# 设置训练网络的一些参数\n",
    "total_train_num = 0\n",
    "total_test_num = 0\n",
    "num_epochs = 20\n",
    "writer = SummaryWriter(\"vit-mps-clearML_logs\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"——————第{}轮训练开始—————\".format(epoch + 1))\n",
    "\n",
    "    # 开始训练\n",
    "    vit.train()\n",
    "    for images, targets in tqdm(train_dataloader):\n",
    "        images = images.to(device)\n",
    "        targets = targets.to(device)\n",
    "        outputs = vit(images)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "\n",
    "        # 优化器优化模型\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_train_num += 1  # 记录训练次数\n",
    "        if total_train_num % 500 == 0:\n",
    "            print(\"训练次数：{}，LOSS：{}\".format(total_train_num, loss.item()))\n",
    "    print()\n",
    "\n",
    "    # 测试步骤开始：\n",
    "    vit.eval()\n",
    "    total_test_loss = 0\n",
    "    total_accuracy = 0\n",
    "    with torch.no_grad():\n",
    "        for images, targets in test_dataloader:\n",
    "            images = images.to(device)\n",
    "            targets = targets.to(device)\n",
    "            outputs = vit(images)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            total_test_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, dim=1)\n",
    "            correct = predicted.eq(targets).sum().item()\n",
    "            total_accuracy += correct\n",
    "\n",
    "    average_test_loss = total_test_loss / len(test_dataloader)\n",
    "    accuracy = total_accuracy / len(test_data)\n",
    "    print(\"test set上 LOSS：{}\".format(total_test_loss))\n",
    "    print(\"test set上的准确率acc：{}\".format(accuracy))\n",
    "    print()\n",
    "    writer.add_scalar(\"test_loss\", average_test_loss, total_test_num)\n",
    "    writer.add_scalar(\"test_accuracy\", accuracy, total_test_num)\n",
    "    total_test_num += 1\n",
    "\n",
    "# Save the model, saving the model will automatically also register it to\n",
    "# ClearML thanks to the automagic hooks\n",
    "vit.train.save_model(\"best_model\")\n",
    "\n",
    "# When a python script ends, the ClearML task is closed automatically. But in\n",
    "# a notebook (that never ends), we need to manually close the task.\n",
    "task.close()\n",
    "\n",
    "writer.flush()\n",
    "writer.close()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e908170f48f5f710"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
